{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from teehr import Evaluation\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "from teehr.models.tables import (\n",
    "    Attribute,\n",
    "    Configuration,\n",
    "    Variable\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a path to the directory where the evaluation will be created\n",
    "TEST_STUDY_DIR = Path(Path().home(), \"temp\", \"test_study\")\n",
    "shutil.rmtree(TEST_STUDY_DIR, ignore_errors=True)\n",
    "TEST_STUDY_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Set a path to the directory where the test data is stored\n",
    "# TEST_DATA_DIR = Path(\"/home/matt/repos/teehr/tests/data/v0_3_test_study\")\n",
    "TEST_DATA_DIR = Path(\"/home/sam/temp/test_study\")\n",
    "GEOJSON_GAGES_FILEPATH = Path(TEST_DATA_DIR, \"geo\", \"gages.geojson\")\n",
    "PRIMARY_TIMESERIES_FILEPATH = Path(\n",
    "    TEST_DATA_DIR, \"timeseries\", \"test_short_obs.parquet\"\n",
    ")\n",
    "CROSSWALK_FILEPATH = Path(TEST_DATA_DIR, \"geo\", \"crosswalk.csv\")\n",
    "SECONDARY_TIMESERIES_FILEPATH = Path(\n",
    "    TEST_DATA_DIR, \"timeseries\", \"test_short_fcast.parquet\"\n",
    ")\n",
    "GEO_FILEPATH = Path(TEST_DATA_DIR, \"geo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Evaluation object\n",
    "eval = Evaluation(dir_path=TEST_STUDY_DIR)\n",
    "\n",
    "# Enable logging\n",
    "eval.enable_logging()\n",
    "\n",
    "# Clone the template\n",
    "eval.clone_template()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the location data (observations)\n",
    "eval.load.import_locations(in_path=GEOJSON_GAGES_FILEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the timeseries data and map over the fields and set constants\n",
    "eval.load.import_primary_timeseries(\n",
    "    in_path=PRIMARY_TIMESERIES_FILEPATH,\n",
    "    field_mapping={\n",
    "        \"reference_time\": \"reference_time\",\n",
    "        \"value_time\": \"value_time\",\n",
    "        \"configuration\": \"configuration_name\",\n",
    "        \"measurement_unit\": \"unit_name\",\n",
    "        \"variable_name\": \"variable_name\",\n",
    "        \"value\": \"value\",\n",
    "        \"location_id\": \"location_id\"\n",
    "    },\n",
    "    constant_field_values={\n",
    "        \"unit_name\": \"m^3/s\",\n",
    "        \"variable_name\": \"streamflow_hourly_inst\",\n",
    "        \"configuration_name\": \"usgs_observations\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the crosswalk data\n",
    "eval.load.import_location_crosswalks(\n",
    "    in_path=CROSSWALK_FILEPATH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the secondary timeseries data and map over the fields and set constants\n",
    "eval.load.import_secondary_timeseries(\n",
    "    in_path=SECONDARY_TIMESERIES_FILEPATH,\n",
    "    field_mapping={\n",
    "        \"reference_time\": \"reference_time\",\n",
    "        \"value_time\": \"value_time\",\n",
    "        \"configuration\": \"configuration_name\",\n",
    "        \"measurement_unit\": \"unit_name\",\n",
    "        \"variable_name\": \"variable_name\",\n",
    "        \"value\": \"value\",\n",
    "        \"location_id\": \"location_id\"\n",
    "    },\n",
    "    constant_field_values={\n",
    "        \"unit_name\": \"m^3/s\",\n",
    "        \"variable_name\": \"streamflow_hourly_inst\",\n",
    "        \"configuration_name\": \"nwm30_retrospective\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some attributes\n",
    "eval.load.add_attribute(\n",
    "    [\n",
    "        Attribute(\n",
    "            name=\"drainage_area\",\n",
    "            type=\"continuous\",\n",
    "            description=\"Drainage area in square kilometers\"\n",
    "        ),\n",
    "        Attribute(\n",
    "            name=\"ecoregion\",\n",
    "            type=\"categorical\",\n",
    "            description=\"Ecoregion\"\n",
    "        ),\n",
    "        Attribute(\n",
    "            name=\"year_2_discharge\",\n",
    "            type=\"continuous\",\n",
    "            description=\"2-yr discharge in cubic meters per second\"\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the location attribute data\n",
    "eval.load.import_location_attributes(\n",
    "    in_path=GEO_FILEPATH,\n",
    "    field_mapping={\"attribute_value\": \"value\"},\n",
    "    pattern=\"test_attr_*.parquet\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the joined timeseries\n",
    "eval.create_joined_timeseries(execute_udf=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "Timeseries, location crosswalks, and location attributes can also be loaded from netcdf files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new Evaluation object\n",
    "shutil.rmtree(TEST_STUDY_DIR, ignore_errors=True)\n",
    "TEST_STUDY_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "ev = Evaluation(dir_path=TEST_STUDY_DIR)\n",
    "\n",
    "# Enable logging\n",
    "ev.enable_logging()\n",
    "\n",
    "# Clone the template\n",
    "ev.clone_template()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The primary locations file with geometry\n",
    "# (TEEHR currently only supports formats readable by geopandas)\n",
    "NETCDF_GEO_FILEPATH = Path(\n",
    "    \"/home/sam/git/teehr/tests/data/test_study/geo/summa_locations.parquet\"\n",
    ")\n",
    "gpd.read_parquet(NETCDF_GEO_FILEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the locations and add the configuration and variable domain entries\n",
    "ev.load.import_locations(in_path=NETCDF_GEO_FILEPATH)\n",
    "\n",
    "ev.load.add_configuration(\n",
    "    Configuration(\n",
    "        name=\"summa\",\n",
    "        type=\"primary\",\n",
    "        description=\"Summa Runoff Data\"\n",
    "    )\n",
    ")\n",
    "\n",
    "ev.load.add_variable(\n",
    "    Variable(\n",
    "        name=\"runoff\",\n",
    "        long_name=\"runoff\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is an example considered a primary timeseries file in netcdf format.\n",
    "NETCDF_TIMESERIES_FILEPATH = Path(\n",
    "    \"/home/sam/git/teehr/tests/data/test_study/timeseries/summa.example.nc\"\n",
    ")\n",
    "# Look at the contents of the netcdf file to determine the field mapping\n",
    "xr.open_dataset(NETCDF_TIMESERIES_FILEPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TEEHR Timeseries table schema includes fields:\n",
    "\n",
    "- reference_time\n",
    "- value_time\n",
    "- configuration_name\n",
    "- unit_name\n",
    "- variable_name\n",
    "- value\n",
    "- location_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the fields in the netcdf file to the fields in the database, defining the constant values\n",
    "summa_field_mapping = {\n",
    "    \"time\": \"value_time\",\n",
    "    \"averageRoutedRunoff_mean\": \"value\",\n",
    "    \"gru\": \"location_id\"\n",
    "}\n",
    "summa_constant_field_values = {\n",
    "    \"unit_name\": \"m^3/s\",\n",
    "    \"variable_name\": \"runoff\",\n",
    "    \"configuration_name\": \"summa\",\n",
    "    \"reference_time\": None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the timeseries data, mapping over the fields and setting constants\n",
    "ev.load.import_primary_timeseries(\n",
    "    in_path=NETCDF_TIMESERIES_FILEPATH,\n",
    "    field_mapping=summa_field_mapping,\n",
    "    constant_field_values=summa_constant_field_values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev.primary_timeseries.to_pandas().head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
