{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ace42340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b218a5fb",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e848e15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input pathing\n",
    "inputDir = Path(Path.home(), 'temp', 'PSU_data', 'preprocessed_inputs')\n",
    "gage_path = Path(inputDir, 'gage_info.csv')\n",
    "ensemble_path = Path(inputDir, 'ensemble_streamflow.csv')\n",
    "hbv_path = Path(inputDir, 'hbv_streamflow.csv')\n",
    "prms_path = Path(inputDir, 'prms_streamflow.csv')\n",
    "sacsma_path = Path(inputDir, 'sacsma_streamflow.csv')\n",
    "\n",
    "# Define export directory\n",
    "outputDir = Path(Path.home(), 'temp', 'PSU_data', 'teehr_inputs')\n",
    "if not outputDir.exists():\n",
    "    outputDir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6f8f2f",
   "metadata": {},
   "source": [
    "### Ingest preprocessed inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6f87f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in gage data and fix leading 0's\n",
    "gage_df = pd.read_csv(gage_path)\n",
    "gage_df['STAID'] = gage_df['STAID'].astype(str)\n",
    "gage_list = list(gage_df['STAID'])\n",
    "gage_bin = []\n",
    "for id in gage_list:\n",
    "    if len(id) == 7:\n",
    "        new_id = f'0{id}'\n",
    "        gage_bin.append(new_id)\n",
    "    else:\n",
    "        gage_bin.append(id)\n",
    "gage_df['STAID'] = gage_bin\n",
    "\n",
    "\n",
    "# read in streamflow data\n",
    "ensemble_df = pd.read_csv(ensemble_path)\n",
    "ensemble_df.rename(columns={'Unnamed: 0':'Date'}, inplace=True)\n",
    "hbv_df = pd.read_csv(hbv_path)\n",
    "hbv_df.rename(columns={'Unnamed: 0':'Date'}, inplace=True)\n",
    "prms_df = pd.read_csv(prms_path)\n",
    "prms_df.rename(columns={'Unnamed: 0':'Date'}, inplace=True)\n",
    "sacsma_df = pd.read_csv(prms_path)\n",
    "sacsma_df.rename(columns={'Unnamed: 0':'Date'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62059799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PSU uses usgs ids for their model ids\n",
    "ensemble_df.columns = [c.replace('d_ensemble-','usgs-') for c in ensemble_df.columns]\n",
    "hbv_df.columns = [c.replace('d_hbv-','usgs-') for c in hbv_df.columns]\n",
    "prms_df.columns = [c.replace('d_prms-','usgs-') for c in prms_df.columns]\n",
    "sacsma_df.columns = [c.replace('d_prms-','usgs-') for c in sacsma_df.columns]  # sacsma preprocessed file had prms heading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7e5283",
   "metadata": {},
   "source": [
    "### Create parquet for each configuration in teehr format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf581a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the streamflow units\n",
    "def convert_streamflow_units(input_df, gage_df):\n",
    "    '''Converts units on streamflow from mm/day to cms.'''\n",
    "    for column in input_df.columns:\n",
    "        if column != 'Date':\n",
    "            # get gage id\n",
    "            column_parts = column.split('-')\n",
    "            gage_id = column_parts[1]\n",
    "            # get area in km\n",
    "            gage_row = gage_df[gage_df['STAID'] == gage_id]\n",
    "            area_km = gage_row['DRAIN_SQKM'].values[0]\n",
    "            # get value in cms\n",
    "            input_df[column] = (input_df[column]*area_km)/86.4  # I gave you the wrong conversion\n",
    "\n",
    "    return input_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12808878",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_df = convert_streamflow_units(input_df=ensemble_df, gage_df=gage_df)\n",
    "hbv_df = convert_streamflow_units(input_df=hbv_df, gage_df=gage_df)\n",
    "prms_df = convert_streamflow_units(input_df=prms_df, gage_df=gage_df)\n",
    "sacsma_df = convert_streamflow_units(input_df=sacsma_df, gage_df=gage_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07ac6298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def teehrify(input_df, configuration_name, outputDir):\n",
    "    '''Converts the PSU DM data to teehr format.'''\n",
    "    # establish output folder\n",
    "    secondary_ts_dir = Path(outputDir, 'secondary_timeseries_TEST') # this will be our test folder to compare normal loading to\n",
    "    if not secondary_ts_dir.exists():\n",
    "        secondary_ts_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # establish counter\n",
    "    len_process = len(input_df.columns)-1\n",
    "    counter = 0\n",
    "\n",
    "    # deconstruct input_df\n",
    "    for column in input_df.columns:\n",
    "        if column != 'Date':\n",
    "            # increment counter and print progress\n",
    "            counter += 1\n",
    "            if counter%100 == 0:\n",
    "                print(f'starting routine for gage #{counter} ({np.round(((counter/len_process)*100),2)}%)')\n",
    "\n",
    "            # assemble data to add rows for a given gage\n",
    "            num_rows = len(input_df)\n",
    "            data = {'reference_time': [None]*num_rows,\n",
    "                    'value_time': pd.to_datetime(input_df['Date'].values),\n",
    "                    'value': input_df[column].values,\n",
    "                    'variable_name': ['streamflow_daily_mean']*num_rows,\n",
    "                    'configuration_name': [configuration_name]*num_rows,\n",
    "                    'unit_name': ['m^3/s']*num_rows,\n",
    "                    'location_id': [column]*num_rows,\n",
    "                    'member': ['None']*num_rows # this is what we are testing for the nullible error around member field\n",
    "                   }\n",
    "            working_df = pd.DataFrame(data)\n",
    "\n",
    "            # drop rows with nan values in the value column\n",
    "            working_df_validated = working_df.dropna(subset=['value'])\n",
    "            if len(working_df_validated) != len(working_df):\n",
    "                print(f'Invalid NaN values found for gage #{counter} -- removed {len(working_df)-len(working_df_validated)} rows')\n",
    "\n",
    "            # Export\n",
    "            outPath = Path(secondary_ts_dir, f'{configuration_name}_{counter}.parquet')\n",
    "            working_df_validated.to_parquet(outPath)\n",
    "\n",
    "    print(f'finished processing {counter} gages!')\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07e48984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting routine for gage #100 (3.7%)\n",
      "starting routine for gage #200 (7.4%)\n",
      "starting routine for gage #300 (11.1%)\n",
      "starting routine for gage #400 (14.8%)\n",
      "starting routine for gage #500 (18.5%)\n",
      "starting routine for gage #600 (22.2%)\n",
      "starting routine for gage #700 (25.9%)\n",
      "starting routine for gage #800 (29.6%)\n",
      "starting routine for gage #900 (33.3%)\n",
      "starting routine for gage #1000 (37.0%)\n",
      "starting routine for gage #1100 (40.7%)\n",
      "starting routine for gage #1200 (44.4%)\n",
      "starting routine for gage #1300 (48.09%)\n",
      "starting routine for gage #1400 (51.79%)\n",
      "starting routine for gage #1500 (55.49%)\n",
      "starting routine for gage #1600 (59.19%)\n",
      "starting routine for gage #1700 (62.89%)\n",
      "starting routine for gage #1800 (66.59%)\n",
      "starting routine for gage #1900 (70.29%)\n",
      "starting routine for gage #2000 (73.99%)\n",
      "starting routine for gage #2100 (77.69%)\n",
      "starting routine for gage #2200 (81.39%)\n",
      "starting routine for gage #2300 (85.09%)\n",
      "starting routine for gage #2400 (88.79%)\n",
      "starting routine for gage #2500 (92.49%)\n",
      "starting routine for gage #2600 (96.19%)\n",
      "starting routine for gage #2700 (99.89%)\n",
      "finished processing 2703 gages!\n"
     ]
    }
   ],
   "source": [
    "teehrify(input_df=ensemble_df, configuration_name='d_ensemble', outputDir=outputDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a7d29fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting routine for gage #100 (3.7%)\n",
      "starting routine for gage #200 (7.4%)\n",
      "starting routine for gage #300 (11.1%)\n",
      "starting routine for gage #400 (14.8%)\n",
      "starting routine for gage #500 (18.5%)\n",
      "starting routine for gage #600 (22.2%)\n",
      "starting routine for gage #700 (25.9%)\n",
      "starting routine for gage #800 (29.6%)\n",
      "starting routine for gage #900 (33.3%)\n",
      "starting routine for gage #1000 (37.0%)\n",
      "starting routine for gage #1100 (40.7%)\n",
      "starting routine for gage #1200 (44.4%)\n",
      "starting routine for gage #1300 (48.09%)\n",
      "starting routine for gage #1400 (51.79%)\n",
      "starting routine for gage #1500 (55.49%)\n",
      "starting routine for gage #1600 (59.19%)\n",
      "starting routine for gage #1700 (62.89%)\n",
      "starting routine for gage #1800 (66.59%)\n",
      "starting routine for gage #1900 (70.29%)\n",
      "starting routine for gage #2000 (73.99%)\n",
      "starting routine for gage #2100 (77.69%)\n",
      "starting routine for gage #2200 (81.39%)\n",
      "starting routine for gage #2300 (85.09%)\n",
      "starting routine for gage #2400 (88.79%)\n",
      "starting routine for gage #2500 (92.49%)\n",
      "starting routine for gage #2600 (96.19%)\n",
      "starting routine for gage #2700 (99.89%)\n",
      "finished processing 2703 gages!\n"
     ]
    }
   ],
   "source": [
    "teehrify(input_df=hbv_df, configuration_name='d_hbv', outputDir=outputDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d452b19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting routine for gage #100 (3.7%)\n",
      "starting routine for gage #200 (7.4%)\n",
      "starting routine for gage #300 (11.1%)\n",
      "starting routine for gage #400 (14.8%)\n",
      "starting routine for gage #500 (18.5%)\n",
      "starting routine for gage #600 (22.2%)\n",
      "starting routine for gage #700 (25.9%)\n",
      "starting routine for gage #800 (29.6%)\n",
      "starting routine for gage #900 (33.3%)\n",
      "starting routine for gage #1000 (37.0%)\n",
      "starting routine for gage #1100 (40.7%)\n",
      "starting routine for gage #1200 (44.4%)\n",
      "starting routine for gage #1300 (48.09%)\n",
      "starting routine for gage #1400 (51.79%)\n",
      "starting routine for gage #1500 (55.49%)\n",
      "starting routine for gage #1600 (59.19%)\n",
      "starting routine for gage #1700 (62.89%)\n",
      "starting routine for gage #1800 (66.59%)\n",
      "starting routine for gage #1900 (70.29%)\n",
      "starting routine for gage #2000 (73.99%)\n",
      "starting routine for gage #2100 (77.69%)\n",
      "starting routine for gage #2200 (81.39%)\n",
      "starting routine for gage #2300 (85.09%)\n",
      "starting routine for gage #2400 (88.79%)\n",
      "starting routine for gage #2500 (92.49%)\n",
      "starting routine for gage #2600 (96.19%)\n",
      "starting routine for gage #2700 (99.89%)\n",
      "finished processing 2703 gages!\n"
     ]
    }
   ],
   "source": [
    "teehrify(input_df=prms_df, configuration_name='d_prms', outputDir=outputDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "978d4c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting routine for gage #100 (3.7%)\n",
      "starting routine for gage #200 (7.4%)\n",
      "starting routine for gage #300 (11.1%)\n",
      "starting routine for gage #400 (14.8%)\n",
      "starting routine for gage #500 (18.5%)\n",
      "starting routine for gage #600 (22.2%)\n",
      "starting routine for gage #700 (25.9%)\n",
      "starting routine for gage #800 (29.6%)\n",
      "starting routine for gage #900 (33.3%)\n",
      "starting routine for gage #1000 (37.0%)\n",
      "starting routine for gage #1100 (40.7%)\n",
      "starting routine for gage #1200 (44.4%)\n",
      "starting routine for gage #1300 (48.09%)\n",
      "starting routine for gage #1400 (51.79%)\n",
      "starting routine for gage #1500 (55.49%)\n",
      "starting routine for gage #1600 (59.19%)\n",
      "starting routine for gage #1700 (62.89%)\n",
      "starting routine for gage #1800 (66.59%)\n",
      "starting routine for gage #1900 (70.29%)\n",
      "starting routine for gage #2000 (73.99%)\n",
      "starting routine for gage #2100 (77.69%)\n",
      "starting routine for gage #2200 (81.39%)\n",
      "starting routine for gage #2300 (85.09%)\n",
      "starting routine for gage #2400 (88.79%)\n",
      "starting routine for gage #2500 (92.49%)\n",
      "starting routine for gage #2600 (96.19%)\n",
      "starting routine for gage #2700 (99.89%)\n",
      "finished processing 2703 gages!\n"
     ]
    }
   ],
   "source": [
    "teehrify(input_df=sacsma_df, configuration_name='d_sacsma', outputDir=outputDir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "teehr-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
