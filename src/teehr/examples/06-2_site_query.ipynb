{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from teehr import Evaluation\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a path to the directory where the evaluation will be created\n",
    "TEST_STUDY_DIR = Path(Path().home(), \"temp\", \"real_study\")\n",
    "TEST_STUDY_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Evaluation object\n",
    "eval = Evaluation(dir_path=TEST_STUDY_DIR)\n",
    "\n",
    "# Enable logging\n",
    "eval.enable_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval.joined_timeseries.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from teehr import Metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval.metrics.query(\n",
    "    order_by=[\"primary_location_id\", \"month\"],\n",
    "    group_by=[\"primary_location_id\", \"month\"],\n",
    "    include_metrics=[\n",
    "        metrics.KlingGuptaEfficiency(),\n",
    "        metrics.NashSutcliffeEfficiency(),\n",
    "        metrics.RelativeBias()\n",
    "    ]\n",
    ").to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "jt_fields = eval.joined_timeseries.field_enum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval.metrics.query(\n",
    "    order_by=[\"primary_location_id\"],\n",
    "    group_by=[\"primary_location_id\"],\n",
    "    include_metrics=[\n",
    "        metrics.KlingGuptaEfficiency(),\n",
    "        metrics.NashSutcliffeEfficiency(),\n",
    "        metrics.RelativeBias()\n",
    "    ]\n",
    ").to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from teehr.models.metrics.bootstrap_models import Bootstrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a bootstrapper with custom parameters.\n",
    "boot = Bootstrappers.CircularBlock(\n",
    "    seed=50,\n",
    "    reps=500,\n",
    "    block_size=10,\n",
    "    quantiles=[0.05, 0.95]\n",
    ")\n",
    "kge = metrics.KlingGuptaEfficiency(bootstrap=boot)\n",
    "kge.output_field_name = \"kge_bootstrap\"\n",
    "\n",
    "include_metrics = [kge, metrics.KlingGuptaEfficiency()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_gdf = eval.metrics.query(\n",
    "    include_metrics=include_metrics,\n",
    "    group_by=[\"primary_location_id\"],\n",
    "    order_by=[\"primary_location_id\"]\n",
    ").to_geopandas()\n",
    "metrics_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg, max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf = eval.metrics.query(\n",
    "    order_by=[\"primary_location_id\", \"month\"],\n",
    "    group_by=[\"primary_location_id\", \"month\"],\n",
    "    include_metrics=[\n",
    "        metrics.KlingGuptaEfficiency(),\n",
    "        metrics.NashSutcliffeEfficiency(),\n",
    "        metrics.RelativeBias()\n",
    "    ]\n",
    ").to_sdf().groupBy(\"primary_location_id\").agg(avg(\"relative_bias\").alias(\"relative_bias_avg\")).toPandas()\n",
    "mdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This does not work.\n",
    "# eval.metrics.query(\n",
    "#     order_by=[\"primary_location_id\", \"month\"],\n",
    "#     group_by=[\"primary_location_id\", \"month\"],\n",
    "#     include_metrics=[\n",
    "#         metrics.KlingGuptaEfficiency(),\n",
    "#         metrics.NashSutcliffeEfficiency(),\n",
    "#         metrics.RelativeBias()\n",
    "#     ]\n",
    "# ).query(\n",
    "#     order_by=[\"primary_location_id\"],\n",
    "#     group_by=[\"primary_location_id\"],\n",
    "#     include_metrics=[\n",
    "#         metrics.PrimaryAverage(\n",
    "#             input_field_names=[\"relative_bias\"],\n",
    "#         )\n",
    "#     ]\n",
    "# ).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    eval.joined_timeseries.to_sdf()\n",
    "    .groupBy(\"primary_location_id\", \"month\").agg(avg(\"primary_value\").alias(\"value_avg\")).orderBy(\"primary_location_id\",\"month\").toPandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    eval.joined_timeseries.to_sdf()\n",
    "    .groupBy(\"primary_location_id\", \"month\").agg(avg(\"primary_value\").alias(\"value_avg\"))\n",
    "    .groupBy(\"primary_location_id\").agg(max(\"value_avg\").alias(\"max_value_avg\"))\n",
    "    .toPandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from teehr import Metrics as metrics\n",
    "\n",
    "import itertools\n",
    "from math import pi\n",
    "import random\n",
    "\n",
    "\n",
    "from bokeh.palettes import Turbo256\n",
    "\n",
    "from bokeh.plotting import show, figure\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = eval.primary_timeseries.to_pandas()\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine bins for unique metadata\n",
    "def timeseries_unique_values(df):\n",
    "    # get unique values of each column, add to dict\n",
    "    columns = df.columns.to_list()\n",
    "    Dict = {}\n",
    "    for column in columns:\n",
    "        Dict[column] = df[column].unique().tolist()\n",
    "\n",
    "    return Dict\n",
    "\n",
    "# create plot schema\n",
    "def timeseries_default_schema(df):\n",
    "\n",
    "    # get unique variable names to determine number of tables\n",
    "    unique_variables = df['variable_name'].unique().tolist()\n",
    "\n",
    "    # init empty dict to store variable-specific plotting combinations\n",
    "    schema = {}\n",
    "\n",
    "    # get all unique plotting permutations for that variable, add to dict\n",
    "    for value in unique_variables:\n",
    "        df_variable = df[df['variable_name'] == value]\n",
    "        unique_column_vals = timeseries_unique_values(df=df_variable)\n",
    "        all_list = [unique_column_vals['configuration_name'],unique_column_vals['location_id']] # add reference time down the line\n",
    "        res = list(itertools.product(*all_list))\n",
    "        schema[value] = res\n",
    "\n",
    "\n",
    "    return schema\n",
    "\n",
    "# creates and displays plot\n",
    "def timeseries_generate_plot(schema, df, variable):\n",
    "\n",
    "    # get list of unique units\n",
    "    unique_units = df['unit_name'].unique().tolist() # add check here to ensure only one unit type\n",
    "\n",
    "    # create color palette\n",
    "    numColors = len(schema[variable])\n",
    "    sampled_colors = random.sample(range(0,len(Turbo256)-1),numColors)\n",
    "    palette = Turbo256\n",
    "    palette_count = 0\n",
    "\n",
    "    # init plot\n",
    "    p = figure(title=\"Click legend entry to toggle display of timeseries\",\n",
    "                y_axis_label=\"{} [{}]\".format(variable,unique_units[0]),\n",
    "                x_axis_label=\"Datetime\",\n",
    "                x_axis_type='datetime',\n",
    "                sizing_mode=\"stretch_width\",\n",
    "                tools=['xwheel_zoom','reset'],\n",
    "                height = 800)\n",
    "\n",
    "    # extract timeseries from dataframe and add to plot\n",
    "    for combo in schema[variable]:\n",
    "        temp = df[(df['configuration_name'] == combo[0]) & (df['location_id'] == combo[1])]\n",
    "        p.line(temp.value_time,\n",
    "                temp.value,\n",
    "                legend_label=\"{} - {}\".format(combo[0],combo[1]),\n",
    "                line_width=1,\n",
    "                color=palette[sampled_colors[palette_count]])\n",
    "        palette_count += 1\n",
    "\n",
    "    # format xaxis\n",
    "    p.xaxis.major_label_orientation = pi/4\n",
    "    p.xaxis.axis_label_text_font_size = '14pt'\n",
    "    p.xaxis.axis_label_text_font_style = 'bold'\n",
    "    p.xaxis.major_label_text_font_size = '12pt'\n",
    "\n",
    "    # format yaxis\n",
    "    p.yaxis.axis_label_text_font_size = '14pt'\n",
    "    p.yaxis.axis_label_text_font_style = 'bold'\n",
    "    p.yaxis.major_label_text_font_size = '12pt'\n",
    "\n",
    "    # format title\n",
    "    p.title.text_font_size = '12pt'\n",
    "\n",
    "    # format legend\n",
    "    p.legend.location = 'top_right'\n",
    "    p.legend.label_text_font_size = '14pt'\n",
    "    p.legend.border_line_width = 1\n",
    "    p.legend.border_line_color = 'black'\n",
    "    p.legend.border_line_alpha = 1.0\n",
    "    p.legend.background_fill_color = 'white'\n",
    "    p.legend.background_fill_alpha = 1.0\n",
    "    p.legend.click_policy = 'hide'\n",
    "\n",
    "    # display plot\n",
    "    show(p)\n",
    "\n",
    "    return\n",
    "\n",
    "# determines how many plots to generate -- main method (i.e. calls all other functions)\n",
    "def timeseries_plot(df):\n",
    "\n",
    "    # generate default plotting schema (used if no args are provided)\n",
    "    schema = timeseries_default_schema(df=df)\n",
    "\n",
    "    # get list of unique parameters which determines number of plots to generate\n",
    "    unique_variables = list(schema.keys())\n",
    "\n",
    "    for variable in unique_variables:\n",
    "\n",
    "        # trim the dataframe to only entries for that unique parameter\n",
    "        df_variable = df[df['variable_name'] == variable]\n",
    "\n",
    "        # generate variable specific plot\n",
    "        timeseries_generate_plot(schema=schema, df=df_variable, variable=variable)\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call plotting function\n",
    "timeseries_plot(df=df_raw)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
