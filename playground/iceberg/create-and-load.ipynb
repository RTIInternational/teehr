{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6136814e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import teehr\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21918262",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_path = str(Path.home() / \"temp\" / \"iceberg\" / \"evaluation\")\n",
    "warehouse_path = str(Path(evaluation_path) / \"spark-warehouse\")\n",
    "catalog_name = \"local\"\n",
    "schema_name = \"db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e929cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://artifacts.unidata.ucar.edu/repository/unidata-all added as a remote repository with the name: repo-1\n",
      "Ivy Default Cache set to: /Users/mdenno/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/mdenno/.ivy2/jars\n",
      "org.apache.sedona#sedona-spark-3.5_2.12 added as a dependency\n",
      "org.apache.iceberg#iceberg-spark-runtime-3.5_2.12 added as a dependency\n",
      "org.datasyslab#geotools-wrapper added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-7e833e56-93a3-46db-bcc3-69f2b8e7aae1;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.sedona#sedona-spark-3.5_2.12;1.7.1 in central\n",
      "\tfound org.apache.sedona#sedona-common;1.7.1 in central\n",
      "\tfound org.apache.commons#commons-math3;3.6.1 in central\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/Users/mdenno/repos/teehr/.venv/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tfound org.locationtech.jts#jts-core;1.20.0 in central\n",
      "\tfound org.wololo#jts2geojson;0.16.1 in central\n",
      "\tfound org.locationtech.spatial4j#spatial4j;0.8 in central\n",
      "\tfound com.google.geometry#s2-geometry;2.0.0 in central\n",
      "\tfound com.google.guava#guava;25.1-jre in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
      "\tfound org.checkerframework#checker-qual;2.0.0 in central\n",
      "\tfound com.google.errorprone#error_prone_annotations;2.1.3 in central\n",
      "\tfound com.google.j2objc#j2objc-annotations;1.1 in central\n",
      "\tfound org.codehaus.mojo#animal-sniffer-annotations;1.14 in central\n",
      "\tfound com.uber#h3;4.1.1 in central\n",
      "\tfound net.sf.geographiclib#GeographicLib-Java;1.52 in central\n",
      "\tfound com.github.ben-manes.caffeine#caffeine;2.9.2 in central\n",
      "\tfound org.checkerframework#checker-qual;3.10.0 in central\n",
      "\tfound com.google.errorprone#error_prone_annotations;2.5.1 in central\n",
      "\tfound org.apache.sedona#sedona-spark-common-3.5_2.12;1.7.1 in central\n",
      "\tfound org.apache.sedona#shade-proto;1.7.1 in central\n",
      "\tfound org.xerial#sqlite-jdbc;3.41.2.2 in central\n",
      "\tfound commons-lang#commons-lang;2.6 in central\n",
      "\tfound graphframes#graphframes;0.8.3-spark3.5-s_2.12 in spark-packages\n",
      "\tfound org.slf4j#slf4j-api;1.7.36 in central\n",
      "\tfound org.scala-lang.modules#scala-collection-compat_2.12;2.5.0 in central\n",
      "\tfound org.beryx#awt-color-factory;1.0.0 in central\n",
      "\tfound org.apache.iceberg#iceberg-spark-runtime-3.5_2.12;1.9.0 in central\n",
      "\tfound org.datasyslab#geotools-wrapper;1.7.1-28.5 in central\n",
      ":: resolution report :: resolve 506ms :: artifacts dl 11ms\n",
      "\t:: modules in use:\n",
      "\tcom.github.ben-manes.caffeine#caffeine;2.9.2 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
      "\tcom.google.errorprone#error_prone_annotations;2.5.1 from central in [default]\n",
      "\tcom.google.geometry#s2-geometry;2.0.0 from central in [default]\n",
      "\tcom.google.guava#guava;25.1-jre from central in [default]\n",
      "\tcom.google.j2objc#j2objc-annotations;1.1 from central in [default]\n",
      "\tcom.uber#h3;4.1.1 from central in [default]\n",
      "\tcommons-lang#commons-lang;2.6 from central in [default]\n",
      "\tgraphframes#graphframes;0.8.3-spark3.5-s_2.12 from spark-packages in [default]\n",
      "\tnet.sf.geographiclib#GeographicLib-Java;1.52 from central in [default]\n",
      "\torg.apache.commons#commons-math3;3.6.1 from central in [default]\n",
      "\torg.apache.iceberg#iceberg-spark-runtime-3.5_2.12;1.9.0 from central in [default]\n",
      "\torg.apache.sedona#sedona-common;1.7.1 from central in [default]\n",
      "\torg.apache.sedona#sedona-spark-3.5_2.12;1.7.1 from central in [default]\n",
      "\torg.apache.sedona#sedona-spark-common-3.5_2.12;1.7.1 from central in [default]\n",
      "\torg.apache.sedona#shade-proto;1.7.1 from central in [default]\n",
      "\torg.beryx#awt-color-factory;1.0.0 from central in [default]\n",
      "\torg.checkerframework#checker-qual;3.10.0 from central in [default]\n",
      "\torg.codehaus.mojo#animal-sniffer-annotations;1.14 from central in [default]\n",
      "\torg.datasyslab#geotools-wrapper;1.7.1-28.5 from central in [default]\n",
      "\torg.locationtech.jts#jts-core;1.20.0 from central in [default]\n",
      "\torg.locationtech.spatial4j#spatial4j;0.8 from central in [default]\n",
      "\torg.scala-lang.modules#scala-collection-compat_2.12;2.5.0 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.36 from central in [default]\n",
      "\torg.wololo#jts2geojson;0.16.1 from central in [default]\n",
      "\torg.xerial#sqlite-jdbc;3.41.2.2 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\torg.checkerframework#checker-qual;2.0.0 by [org.checkerframework#checker-qual;3.10.0] in [default]\n",
      "\tcom.google.errorprone#error_prone_annotations;2.1.3 by [com.google.errorprone#error_prone_annotations;2.5.1] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   28  |   0   |   0   |   2   ||   26  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-7e833e56-93a3-46db-bcc3-69f2b8e7aae1\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 26 already retrieved (0kB/10ms)\n",
      "25/06/03 21:55:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from sedona.spark import *\n",
    "\n",
    "config = (\n",
    "    SedonaContext.builder()\n",
    "    .config(\n",
    "        \"spark.jars.packages\",\n",
    "        \"org.apache.sedona:sedona-spark-3.5_2.12:1.7.1,\"\n",
    "        \"org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.9.0,\"\n",
    "        \"org.datasyslab:geotools-wrapper:1.7.1-28.5\"\n",
    "    )\n",
    "    .config(\n",
    "        \"spark.jars.repositories\",\n",
    "        \"https://artifacts.unidata.ucar.edu/repository/unidata-all\",\n",
    "    )\n",
    "    .config(\n",
    "        \"spark.sql.extensions\",\n",
    "        \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\"\n",
    "    )\n",
    "    .config(\n",
    "        f\"spark.sql.catalog.{catalog_name}\",\n",
    "        \"org.apache.iceberg.spark.SparkCatalog\"\n",
    "    )\n",
    "    .config(\n",
    "        f\"spark.sql.catalog.{catalog_name}.type\", \"hadoop\"\n",
    "    )\n",
    "    .config(\n",
    "        f\"spark.sql.catalog.{catalog_name}.warehouse\",\n",
    "        f\"{warehouse_path}/{catalog_name}\"\n",
    "    )\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "    .config(\"spark.hadoop.fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.AnonymousAWSCredentialsProvider\")\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"UTC\")\n",
    "    .config(\"spark.driver.host\", \"localhost\")\n",
    "    .config(\"spark.driver.bindAddress\", \"localhost\")\n",
    "    .config(\"spark.driver.memory\", \"16g\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "sedona = SedonaContext.create(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d086ec8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete existing Evaluation (useful when testing)\n",
    "shutil.rmtree(evaluation_path, ignore_errors=True)\n",
    "\n",
    "# Create an Evaluation object and create the directory\n",
    "ev = teehr.Evaluation(\n",
    "    dir_path=evaluation_path,\n",
    "    create_dir=True,\n",
    "    spark=sedona\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15b39ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e0_2_location_example</td>\n",
       "      <td>Example evaluation datsets with 2 USGS gages</td>\n",
       "      <td>s3a://ciroh-rti-public-data/teehr-data-warehou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e1_camels_daily_streamflow</td>\n",
       "      <td>Daily average streamflow at ther Camels basins</td>\n",
       "      <td>s3a://ciroh-rti-public-data/teehr-data-warehou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e2_camels_hourly_streamflow</td>\n",
       "      <td>Hourly instantaneous streamflow at ther Camels...</td>\n",
       "      <td>s3a://ciroh-rti-public-data/teehr-data-warehou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e3_usgs_hourly_streamflow</td>\n",
       "      <td>Hourly instantaneous streamflow at USGS CONUS ...</td>\n",
       "      <td>s3a://ciroh-rti-public-data/teehr-data-warehou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e4_nwm_operational</td>\n",
       "      <td>Empty template to load and evaluate NWM operat...</td>\n",
       "      <td>s3a://ciroh-rti-public-data/teehr-data-warehou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          name  \\\n",
       "0        e0_2_location_example   \n",
       "1   e1_camels_daily_streamflow   \n",
       "2  e2_camels_hourly_streamflow   \n",
       "3    e3_usgs_hourly_streamflow   \n",
       "4           e4_nwm_operational   \n",
       "\n",
       "                                         description  \\\n",
       "0       Example evaluation datsets with 2 USGS gages   \n",
       "1     Daily average streamflow at ther Camels basins   \n",
       "2  Hourly instantaneous streamflow at ther Camels...   \n",
       "3  Hourly instantaneous streamflow at USGS CONUS ...   \n",
       "4  Empty template to load and evaluate NWM operat...   \n",
       "\n",
       "                                                 url  \n",
       "0  s3a://ciroh-rti-public-data/teehr-data-warehou...  \n",
       "1  s3a://ciroh-rti-public-data/teehr-data-warehou...  \n",
       "2  s3a://ciroh-rti-public-data/teehr-data-warehou...  \n",
       "3  s3a://ciroh-rti-public-data/teehr-data-warehou...  \n",
       "4  s3a://ciroh-rti-public-data/teehr-data-warehou...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev.list_s3_evaluations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e8ff3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/03 21:55:43 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "25/06/03 21:56:05 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Clone the e0_camels_daily_streamflow evaluation from the S3 bucket\n",
    "ev.clone_from_s3(\"e1_camels_daily_streamflow\")\n",
    "# ev.clone_from_s3(\"e0_2_location_example\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edd3afa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying schema version 1 to local.db\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying schema version 2 to local.db\n",
      "Applying schema version 3 to local.db\n",
      "Applying schema version 4 to local.db\n",
      "Schema evolution completed for local.\n"
     ]
    }
   ],
   "source": [
    "import apply_migrations\n",
    "import importlib\n",
    "importlib.reload(apply_migrations)\n",
    "\n",
    "apply_migrations.evolve_catalog_schema(sedona, catalog_name, schema_name)\n",
    "\n",
    "print(f\"Schema evolution completed for {catalog_name}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f013f549",
   "metadata": {},
   "outputs": [],
   "source": [
    "units_sdf = ev.units.to_sdf()\n",
    "units_sdf.writeTo(\"local.db.units\").append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ada91c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration_sdf = ev.configurations.to_sdf()\n",
    "configuration_sdf.writeTo(\"local.db.configurations\").append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ec5bcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_sdf = ev.variables.to_sdf()\n",
    "variables_sdf.writeTo(\"local.db.variables\").append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "561da1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_sdf = ev.attributes.to_sdf()\n",
    "attributes_sdf.writeTo(\"local.db.attributes\").append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48a0af6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_sdf = ev.locations.to_sdf()\n",
    "locations_sdf.writeTo(\"local.db.locations\").append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a98df88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+-------------------+\n",
      "|  location_id|attribute_name|              value|\n",
      "+-------------+--------------+-------------------+\n",
      "|usgs-01013500|        q_mean| 44.467109455834866|\n",
      "|usgs-01022500|        q_mean| 14.786380055715862|\n",
      "|usgs-01030500|        q_mean|  77.36721025688733|\n",
      "|usgs-01031500|        q_mean|  18.13589110971241|\n",
      "|usgs-01047000|        q_mean|  23.09950986229729|\n",
      "|usgs-01052500|        q_mean| 10.959371324254077|\n",
      "|usgs-01054200|        q_mean|   5.70061348678967|\n",
      "|usgs-01055000|        q_mean|  6.623313284003387|\n",
      "|usgs-01057000|        q_mean|   4.01856522562012|\n",
      "|usgs-01073000|        q_mean| 0.6170135822904296|\n",
      "|usgs-01078000|        q_mean|  4.515503797876271|\n",
      "|usgs-01123000|        q_mean| 1.5623952797949385|\n",
      "|usgs-01134500|        q_mean|  4.684171708725575|\n",
      "|usgs-01137500|        q_mean|  6.248845351029678|\n",
      "|usgs-01139000|        q_mean|  5.007937386091005|\n",
      "|usgs-01139800|        q_mean|0.48647037402160476|\n",
      "|usgs-01142500|        q_mean|  1.575443288786391|\n",
      "|usgs-01144000|        q_mean| 38.446541881905574|\n",
      "|usgs-01169000|        q_mean|   5.96782298557733|\n",
      "|usgs-01170100|        q_mean|  2.694592109426571|\n",
      "+-------------+--------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "location_attrs_sdf = ev.location_attributes.to_sdf()\n",
    "location_attrs_sdf.writeTo(\"local.db.location_attributes\").append()\n",
    "location_attrs_sdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0af27917",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------+----------+---------+-------------+------------------+--------------------+\n",
      "|reference_time|         value_time|     value|unit_name|  location_id|configuration_name|       variable_name|\n",
      "+--------------+-------------------+----------+---------+-------------+------------------+--------------------+\n",
      "|          NULL|1992-10-30 00:00:00|0.44481045|    m^3/s|usgs-07196900| usgs_observations|streamflow_daily_...|\n",
      "|          NULL|1992-10-31 00:00:00| 0.2881239|    m^3/s|usgs-07196900| usgs_observations|streamflow_daily_...|\n",
      "|          NULL|1992-11-01 00:00:00|0.67913234|    m^3/s|usgs-07196900| usgs_observations|streamflow_daily_...|\n",
      "|          NULL|1992-11-02 00:00:00|0.56987655|    m^3/s|usgs-07196900| usgs_observations|streamflow_daily_...|\n",
      "|          NULL|1992-11-03 00:00:00|0.33697048|    m^3/s|usgs-07196900| usgs_observations|streamflow_daily_...|\n",
      "|          NULL|1992-11-04 00:00:00|0.24730046|    m^3/s|usgs-07196900| usgs_observations|streamflow_daily_...|\n",
      "|          NULL|1992-11-05 00:00:00|0.20529714|    m^3/s|usgs-07196900| usgs_observations|streamflow_daily_...|\n",
      "|          NULL|1992-11-06 00:00:00|0.17839612|    m^3/s|usgs-07196900| usgs_observations|streamflow_daily_...|\n",
      "|          NULL|1992-11-07 00:00:00|0.16175999|    m^3/s|usgs-07196900| usgs_observations|streamflow_daily_...|\n",
      "|          NULL|1992-11-08 00:00:00|0.15503474|    m^3/s|usgs-07196900| usgs_observations|streamflow_daily_...|\n",
      "|          NULL|1992-11-09 00:00:00| 0.1500793|    m^3/s|usgs-07196900| usgs_observations|streamflow_daily_...|\n",
      "|          NULL|1992-11-10 00:00:00|0.15326494|    m^3/s|usgs-07196900| usgs_observations|streamflow_daily_...|\n",
      "|          NULL|1992-11-11 00:00:00| 2.6432595|    m^3/s|usgs-07196900| usgs_observations|streamflow_daily_...|\n",
      "|          NULL|1992-11-12 00:00:00|  8.203627|    m^3/s|usgs-07196900| usgs_observations|streamflow_daily_...|\n",
      "|          NULL|1992-11-13 00:00:00| 2.2606282|    m^3/s|usgs-07196900| usgs_observations|streamflow_daily_...|\n",
      "|          NULL|1992-11-14 00:00:00| 1.3615683|    m^3/s|usgs-07196900| usgs_observations|streamflow_daily_...|\n",
      "|          NULL|1992-11-15 00:00:00| 1.0170467|    m^3/s|usgs-07196900| usgs_observations|streamflow_daily_...|\n",
      "|          NULL|1992-11-16 00:00:00| 0.8223684|    m^3/s|usgs-07196900| usgs_observations|streamflow_daily_...|\n",
      "|          NULL|1992-11-17 00:00:00| 0.7043815|    m^3/s|usgs-07196900| usgs_observations|streamflow_daily_...|\n",
      "|          NULL|1992-11-18 00:00:00|0.61117196|    m^3/s|usgs-07196900| usgs_observations|streamflow_daily_...|\n",
      "+--------------+-------------------+----------+---------+-------------+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "location_attrs_sdf = ev.primary_timeseries.to_sdf()\n",
    "location_attrs_sdf.writeTo(\"local.db.primary_timeseries\").append()\n",
    "location_attrs_sdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7eb68e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 55:==================================================>     (10 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+---------+--------------+------+-------------------+--------------------+--------------+\n",
      "|         value_time|     value|unit_name|   location_id|member| configuration_name|       variable_name|reference_time|\n",
      "+-------------------+----------+---------+--------------+------+-------------------+--------------------+--------------+\n",
      "|1989-01-01 00:00:00|0.19999999|    m^3/s|nwm30-10025746|  NULL|nwm30_retrospective|streamflow_daily_...|          NULL|\n",
      "|1989-01-02 00:00:00|0.19999999|    m^3/s|nwm30-10025746|  NULL|nwm30_retrospective|streamflow_daily_...|          NULL|\n",
      "|1989-01-03 00:00:00|0.19999999|    m^3/s|nwm30-10025746|  NULL|nwm30_retrospective|streamflow_daily_...|          NULL|\n",
      "|1989-01-04 00:00:00|0.19999999|    m^3/s|nwm30-10025746|  NULL|nwm30_retrospective|streamflow_daily_...|          NULL|\n",
      "|1989-01-05 00:00:00|0.19874999|    m^3/s|nwm30-10025746|  NULL|nwm30_retrospective|streamflow_daily_...|          NULL|\n",
      "|1989-01-06 00:00:00|      0.19|    m^3/s|nwm30-10025746|  NULL|nwm30_retrospective|streamflow_daily_...|          NULL|\n",
      "|1989-01-07 00:00:00|      0.19|    m^3/s|nwm30-10025746|  NULL|nwm30_retrospective|streamflow_daily_...|          NULL|\n",
      "|1989-01-08 00:00:00|      0.19|    m^3/s|nwm30-10025746|  NULL|nwm30_retrospective|streamflow_daily_...|          NULL|\n",
      "|1989-01-09 00:00:00|      0.19|    m^3/s|nwm30-10025746|  NULL|nwm30_retrospective|streamflow_daily_...|          NULL|\n",
      "|1989-01-10 00:00:00|      0.19|    m^3/s|nwm30-10025746|  NULL|nwm30_retrospective|streamflow_daily_...|          NULL|\n",
      "|1989-01-11 00:00:00|      0.19|    m^3/s|nwm30-10025746|  NULL|nwm30_retrospective|streamflow_daily_...|          NULL|\n",
      "|1989-01-12 00:00:00|      0.19|    m^3/s|nwm30-10025746|  NULL|nwm30_retrospective|streamflow_daily_...|          NULL|\n",
      "|1989-01-13 00:00:00|      0.19|    m^3/s|nwm30-10025746|  NULL|nwm30_retrospective|streamflow_daily_...|          NULL|\n",
      "|1989-01-14 00:00:00|      0.19|    m^3/s|nwm30-10025746|  NULL|nwm30_retrospective|streamflow_daily_...|          NULL|\n",
      "|1989-01-15 00:00:00|      0.19|    m^3/s|nwm30-10025746|  NULL|nwm30_retrospective|streamflow_daily_...|          NULL|\n",
      "|1989-01-16 00:00:00|      0.19|    m^3/s|nwm30-10025746|  NULL|nwm30_retrospective|streamflow_daily_...|          NULL|\n",
      "|1989-01-17 00:00:00|      0.19|    m^3/s|nwm30-10025746|  NULL|nwm30_retrospective|streamflow_daily_...|          NULL|\n",
      "|1989-01-18 00:00:00|      0.19|    m^3/s|nwm30-10025746|  NULL|nwm30_retrospective|streamflow_daily_...|          NULL|\n",
      "|1989-01-19 00:00:00|      0.19|    m^3/s|nwm30-10025746|  NULL|nwm30_retrospective|streamflow_daily_...|          NULL|\n",
      "|1989-01-20 00:00:00|      0.19|    m^3/s|nwm30-10025746|  NULL|nwm30_retrospective|streamflow_daily_...|          NULL|\n",
      "+-------------------+----------+---------+--------------+------+-------------------+--------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "secondary_timeseries_sdf = ev.secondary_timeseries.to_sdf()\n",
    "secondary_timeseries_sdf.writeTo(\"local.db.secondary_timeseries\").append()\n",
    "secondary_timeseries_sdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91340bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------------------+\n",
      "|primary_location_id|secondary_location_id|\n",
      "+-------------------+---------------------+\n",
      "|      usgs-01030500|           nwm30-3923|\n",
      "|      usgs-04057510|         nwm30-272589|\n",
      "|      usgs-11299600|         nwm30-348419|\n",
      "|      usgs-07195800|         nwm30-399452|\n",
      "|      usgs-07197000|         nwm30-400496|\n",
      "|      usgs-07196900|         nwm30-400822|\n",
      "|      usgs-03213700|         nwm30-435154|\n",
      "|      usgs-03281500|         nwm30-503758|\n",
      "|      usgs-07335700|         nwm30-588170|\n",
      "|      usgs-01013500|         nwm30-724696|\n",
      "|      usgs-07083000|         nwm30-916821|\n",
      "|      usgs-07346045|        nwm30-1017865|\n",
      "|      usgs-02221525|        nwm30-1056599|\n",
      "|      usgs-10234500|        nwm30-1215135|\n",
      "|      usgs-09035900|        nwm30-1238533|\n",
      "|      usgs-08050800|        nwm30-1275870|\n",
      "|      usgs-09047700|        nwm30-1314083|\n",
      "|      usgs-09066300|        nwm30-1319214|\n",
      "|      usgs-09066200|        nwm30-1320244|\n",
      "|      usgs-09065500|        nwm30-1320264|\n",
      "+-------------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "location_crosswalk_sdf = ev.location_crosswalks.to_sdf()\n",
    "location_crosswalk_sdf.writeTo(\"local.db.location_crosswalks\").append()\n",
    "location_crosswalk_sdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3470218",
   "metadata": {},
   "outputs": [],
   "source": [
    "sedona.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc543c2",
   "metadata": {},
   "source": [
    "- Create joined timeseries needs some filters so that we can incrementally create the joined timeseries.  \n",
    "- Joined timeseries should maybe only contain the joined ts.  That join process does not parallelize well.  Other joins do."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2323ecf",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
