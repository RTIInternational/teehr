{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39ea74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "import teehr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe740fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hvplot.pandas  # noqa\n",
    "import holoviews as hv\n",
    "from bokeh.models import DatetimeTickFormatter\n",
    "\n",
    "plot_width = 800\n",
    "plot_height = 500\n",
    "plot_bgcolor = \"#F5F5F5\"\n",
    "\n",
    "hv.opts.defaults(\n",
    "    hv.opts.Curve(width=plot_width, height=plot_height, bgcolor=plot_bgcolor),\n",
    "    hv.opts.Scatter(width=plot_width, height=plot_height, bgcolor=plot_bgcolor),\n",
    "    hv.opts.Area(width=plot_width, height=plot_height, bgcolor=plot_bgcolor),\n",
    "    hv.opts.Points(width=plot_width, height=plot_height, bgcolor=plot_bgcolor),\n",
    ")\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac97a5ab",
   "metadata": {},
   "source": [
    "Let's use a pre-created test Evaluation from the HEFS s3 bucket.\n",
    "\n",
    "Contents:\n",
    "- 1 USGS location, 5 years of hourly streamflow\n",
    "- 1 HEFS locations\n",
    "  - 5 years of hindcasts\n",
    "  - 1 per day, 6-hour timesteps\n",
    "  - 66 members each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c0ff98",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMP_DIR = Path(Path.home(), \"temp\", \"teehr_playground\")\n",
    "# shutil.rmtree(TEMP_DIR, ignore_errors=True)\n",
    "# TEMP_DIR.mkdir(parents=True)\n",
    "# path_str = TEMP_DIR.as_posix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49bae2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "! wget -P \"$path_str\" https://ciroh-rti-hefs-data.s3.us-east-2.amazonaws.com/teehr/test_evaluations/ckfn6bvr_evaluation.tar.gz\n",
    "! tar -xzvf \"$path_str\"/ckfn6bvr_evaluation.tar.gz -C \"$path_str\"\n",
    "! rm \"$path_str\"/ckfn6bvr_evaluation.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fc1adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = teehr.Evaluation(dir_path=Path(TEMP_DIR, \"ckfn6bvr_evaluation\"))\n",
    "ev.enable_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a567de02",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev.locations.to_geopandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2701eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev.location_crosswalks.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8b088d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prim_df = ev.primary_timeseries.filter(\n",
    "    \"configuration_name = 'usgs_observations'\"\n",
    ").to_pandas()\n",
    "\n",
    "prim_plot = prim_df.hvplot(\n",
    "    x=\"value_time\",\n",
    "    y=\"value\",\n",
    "    xlabel=\"Date\",\n",
    "    ylabel=\"Streamflow (cfs)\",\n",
    "    width=plot_width,\n",
    "    height=plot_height,\n",
    "    bgcolor=plot_bgcolor,\n",
    "    line_color=\"blue\",\n",
    "    line_width=2,\n",
    "    grid=True,\n",
    ")\n",
    "prim_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ae8f3b",
   "metadata": {},
   "source": [
    "### Skill score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd0a4d5",
   "metadata": {},
   "source": [
    "The skill of a model relative to some reference model/timeseries such as climatology can be computed. Methods to create this reference timeseries (or hindcast) are also included.\n",
    "\n",
    "Here, we'll first compute \"climatology\" based on the 5-year USGS timeseries, taking the mean of the primary timeseries at each hour of the year. Since we're creating a new timeseries, we also need to add a configuration object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08270c58",
   "metadata": {},
   "source": [
    "### Calculate the mean of the USGS observations by hour-of-year, saving as a new primary timeseries (\"hourly normals\" or \"climatology\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84c7420",
   "metadata": {},
   "source": [
    "We can make use of TEEHR's timeseries generator classes to perform this operation. Hourly normals are considered a \"signature\" timeseries in TEEHR, since they operate on a single timeseries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d9c749",
   "metadata": {},
   "outputs": [],
   "source": [
    "from teehr import SignatureTimeseriesGenerators as sts\n",
    "\n",
    "from teehr.models.filters import TableFilter\n",
    "\n",
    "# Define the operation to perform.\n",
    "ts_normals = sts.Normals()\n",
    "ts_normals.temporal_resolution = \"hour_of_year\"\n",
    "ts_normals.summary_statistic = \"mean\"           # the default\n",
    "\n",
    "# Define the timeseries to use as input to the operation.\n",
    "input_ts = TableFilter()\n",
    "input_ts.table_name = \"primary_timeseries\"\n",
    "input_ts.filters = [\n",
    "    \"configuration_name = 'usgs_observations'\",\n",
    "    \"unit_name = 'm^3/s'\",\n",
    "    \"variable_name = 'streamflow_hourly_inst'\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2b822c",
   "metadata": {},
   "source": [
    "Note. We see some warnings here (and a performance hit) related to window operation which forward and back-fills NaN values. This is because there is only a single partition in this case (defined by: [\"location_id\", \"variable_name\", \"unit_name\", \"configuration_name\", \"reference_time\"]). Might need a better approach to this edge case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2072214d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ev.generate.signature_timeseries(\n",
    "    method=ts_normals,\n",
    "    input_table_filter=input_ts,\n",
    "    start_datetime=\"2000-01-01T12:00:00\",\n",
    "    end_datetime=\"2005-01-31T12:00:00\",\n",
    "    timestep=\"1 hour\"\n",
    ").write()  # default destination: \"primary_timeseries\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84de680",
   "metadata": {},
   "outputs": [],
   "source": [
    "clim_df = ev.primary_timeseries.filter(\n",
    "    \"variable_name = 'streamflow_hour_of_year_mean'\"\n",
    ").to_pandas()\n",
    "\n",
    "clim_plot = clim_df.hvplot(\n",
    "    x=\"value_time\",\n",
    "    y=\"value\",\n",
    "    xlabel=\"Date\",\n",
    "    ylabel=\"Streamflow (cfs)\",\n",
    "    width=plot_width,\n",
    "    height=plot_height,\n",
    "    bgcolor=plot_bgcolor,\n",
    "    line_color=\"magenta\",\n",
    "    line_width=2,\n",
    "    grid=True,\n",
    ")\n",
    "prim_plot * clim_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880b8d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "\n",
    "def adjust_hour_of_year(date):\n",
    "    if calendar.isleap(date.year):\n",
    "        if date.month == 2 and date.day == 29:\n",
    "            # Assign to Feb.28 during leap years\n",
    "            return 58 * 24 + date.hour\n",
    "        elif date.month > 2:\n",
    "            return (date.dayofyear - 2) * 24 + date.hour\n",
    "        else:\n",
    "            return (date.dayofyear - 1) * 24 + date.hour\n",
    "    else:\n",
    "        return (date.dayofyear - 1) * 24 + date.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c14c34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prim_df[\"hour_of_year\"] = prim_df[\"value_time\"].apply(adjust_hour_of_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a2fdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "prim_df.hour_of_year.min(), prim_df.hour_of_year.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b960a700",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_df = prim_df[[\"value_time\", \"value\", \"hour_of_year\"]].groupby([\"hour_of_year\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f658721",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_df = prim_df.groupby([\"hour_of_year\"])[\"value\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95403f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1698e33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = prim_df.join(manual_df, on=\"hour_of_year\", rsuffix=\"_manual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2900ece7",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_plot = joined_df.hvplot(\n",
    "    x=\"value_time\",\n",
    "    y=\"value_manual\",\n",
    "    xlabel=\"Date\",\n",
    "    ylabel=\"Streamflow (cfs)\",\n",
    "    width=plot_width,\n",
    "    height=plot_height,\n",
    "    bgcolor=plot_bgcolor,\n",
    "    line_color=\"black\",\n",
    "    line_width=1,\n",
    "    grid=True,\n",
    "    # alpha=0.75,\n",
    ")\n",
    "clim_plot * manual_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb322c1",
   "metadata": {},
   "source": [
    "### Assemble a reference forecast by assigning the climatology values to a HEFS forecast member template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547ac58d",
   "metadata": {},
   "source": [
    "To compare the performance of the HEFS hindcast against a hindcast based on climatology, we can create a \"reference forecast\" (hindcast in this case) based on the climatology timeseries we just created. We'll assign values from the climatology timeseries to a member of the HEFS hindcast according to the value_time. In this case we also aggregate to 6-hr time steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca780b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev.secondary_timeseries.distinct_values(\"configuration_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484ea3aa",
   "metadata": {},
   "source": [
    "Here we'll make use of a Benchmark Forecast Generator class to perform the operation. These create a forecast by assigning values from one timeseries to a template forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8308027f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from teehr import BenchmarkForecastGenerators as bm\n",
    "\n",
    "ref_fcst = bm.ReferenceForecast()\n",
    "\n",
    "reference_ts = TableFilter(\n",
    "    table_name=\"primary_timeseries\",\n",
    "    filters=[\n",
    "        \"configuration_name = 'usgs_observations'\",\n",
    "        \"unit_name = 'm^3/s'\",\n",
    "        \"variable_name = 'streamflow_hour_of_year_mean'\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "template_ts = TableFilter(\n",
    "    table_name=\"secondary_timeseries\",\n",
    "    filters=[\n",
    "        \"configuration_name = 'MEFP'\",\n",
    "        \"variable_name = 'streamflow_hourly_inst'\",\n",
    "        \"unit_name = 'm^3/s'\",\n",
    "        \"member = '1993'\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c16bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ev.configurations.add(\n",
    "    [\n",
    "        teehr.Configuration(\n",
    "            name=\"reference_climatology_forecast\",\n",
    "            type=\"secondary\",\n",
    "            description=\"Reference forecast based on USGS climatology summarized by hour of year\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "ev.generate.benchmark_forecast(\n",
    "    method=ref_fcst,\n",
    "    reference_timeseries=reference_ts,\n",
    "    template_timeseries=template_ts,\n",
    "    output_configuration_name=\"reference_climatology_forecast\"\n",
    ").write(destination_table=\"secondary_timeseries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6a25b9",
   "metadata": {},
   "source": [
    "### Let's explore the data a bit\n",
    "\n",
    "We'll calculate the ensemble min, max, and mean of the HEFS hindcasts so we can visualize the spread "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efc07cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg, min, max, lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef9e57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hefs_sdf = ev.secondary_timeseries.filter(\"configuration_name = 'MEFP'\").to_sdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb27839",
   "metadata": {},
   "source": [
    "Calculate mean, min, and max across the HEFS ensemble members."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149dad50",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_sdf = hefs_sdf.groupBy(\n",
    "    \"value_time\",\n",
    "    \"reference_time\",\n",
    "    \"location_id\",\n",
    "    \"unit_name\",\n",
    "    \"configuration_name\",\n",
    "    \"variable_name\"\n",
    ") \\\n",
    ".agg(\n",
    "    avg(\"value\").alias(\"mean_value\"),\n",
    "    max(\"value\").alias(\"max_value\"),\n",
    "    min(\"value\").alias(\"min_value\")\n",
    ") \\\n",
    ".withColumn(\"member\", lit(\"1953\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fade92",
   "metadata": {},
   "outputs": [],
   "source": [
    "join_sdf = stats_sdf.join(\n",
    "    hefs_sdf,\n",
    "    on=[\n",
    "        \"value_time\",\n",
    "        \"reference_time\",\n",
    "        \"location_id\",\n",
    "        \"unit_name\",\n",
    "        \"configuration_name\",\n",
    "        \"variable_name\",\n",
    "        \"member\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea4ef4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "hefs_stats_df = join_sdf.toPandas()\n",
    "hefs_stats_df.set_index(\"value_time\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af80a4df",
   "metadata": {},
   "source": [
    "#### Let's choose a single reference time (forecast) to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60021f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_reference_time = \"2002-05-07 12:00:00\"\n",
    "\n",
    "# Ensemble stats (min, max, mean).\n",
    "hefs_stats_subset_df = hefs_stats_df[hefs_stats_df.reference_time == f\"{example_reference_time}\"].copy()\n",
    "\n",
    "# The \"reference\" forecast assembled from climatology (mean of hour-of-year).\n",
    "ref_subset_df = ev.secondary_timeseries \\\n",
    "    .filter(\"configuration_name = 'reference_climatology_forecast'\") \\\n",
    "    .filter(f\"reference_time = '{example_reference_time}'\") \\\n",
    "    .to_pandas()\n",
    "ref_subset_df.set_index(\"value_time\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9896b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clim_df = ev.primary_timeseries \\\n",
    "    .query(\n",
    "        filters=[\n",
    "            \"variable_name = 'streamflow_hour_of_year_mean'\",\n",
    "            \"value_time >='2002-05-07 12:00'\",\n",
    "            \"value_time <= '2002-06-06 12:00'\"\n",
    "        ]\n",
    "    ).to_pandas()\n",
    "clim_df.set_index(\"value_time\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5a43ed",
   "metadata": {},
   "source": [
    "#### Let's plot an overlay of the HEFS ensemble spread, HEFS ensemble mean, Reference forecast (climatology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30706498",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_fcst_plot = ref_subset_df.hvplot.line(\n",
    "    y=\"value\",\n",
    "    legend=True,\n",
    "    line_color=\"purple\",\n",
    "    label=\"Reference Forecast from Climatology\",\n",
    "    alpha=0.8\n",
    ")\n",
    "clim_plot = clim_df.hvplot.line(\n",
    "    y=\"value\",\n",
    "    legend=True,\n",
    "    line_color=\"blue\",\n",
    "    label=\"USGS Hourly Climatology\"\n",
    ")\n",
    "hefs_mean_plot = hefs_stats_subset_df.hvplot.line(\n",
    "    y=\"mean_value\",\n",
    "    # by=[\"reference_time\", \"member\"],\n",
    "    legend=True,\n",
    "    label=\"Ensemble mean\",\n",
    "    alpha=0.8,\n",
    "    line_color=\"black\"\n",
    ")\n",
    "hefs_shaded_plot = hefs_stats_subset_df.hvplot.area(\n",
    "    y=\"min_value\",\n",
    "    y2=\"max_value\",\n",
    "    color='lightblue',\n",
    "    alpha=0.5,\n",
    "    legend=True,\n",
    "    label=\"HEFS ensemble spread\",\n",
    "    grid=True\n",
    ")\n",
    "hefs_shaded_plot * hefs_mean_plot * clim_plot * ref_fcst_plot.opts(title=f\"{example_reference_time} Forecast\", ylabel=\"Discharge (cms)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9f8539",
   "metadata": {},
   "source": [
    "### Calculate CRPSS\n",
    "\n",
    "First we need to re-create the joined timeseries table, so that it includes our new timeseries data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c981ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ev.joined_timeseries.create(execute_scripts=True, add_attrs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76b007f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev.joined_timeseries.distinct_values(\"configuration_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b94f3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "crps = teehr.ProbabilisticMetrics.CRPS()\n",
    "crps.summary_func = np.mean\n",
    "crps.estimator = \"pwm\"\n",
    "crps.backend = \"numba\"\n",
    "crps.reference_configuration = \"reference_climatology_forecast\"  # this triggers to skill score calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9fd21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "include_metrics = [crps]\n",
    "metrics_df = ev.metrics.query(\n",
    "    include_metrics=include_metrics,\n",
    "    group_by=[\n",
    "        \"primary_location_id\",\n",
    "        \"configuration_name\",\n",
    "        \"season\"\n",
    "    ],\n",
    "    order_by=[\"configuration_name\"],\n",
    ").to_pandas()\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728cd2f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "teehr-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
