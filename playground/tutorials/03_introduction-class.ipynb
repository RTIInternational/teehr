{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 Introduction\n",
    "In this notebook we will explore the Evaluation schema through the Evaluation class interface. To do so, we first need to create an Evaluation and populate it with data. There are many ways to do this ranging from cloneing a complete Evaluation from the TEEHR S3 bucket that already contains all the nessesary data, to cloning a blank template and populating the tables with all the nessesary data using the builtin loading and fetching methods.  In this exercise we are going to clone a complete Evaluation and explore the tables using the TEEHR Evaluation table subclasses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new Evaluation\n",
    "First we will import the the TEEHR Evaluation class and create a new instance that points to a directory where the evaluation data will be stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/05 14:43:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from teehr import Evaluation\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the directory where the Evaluation will be created\n",
    "test_eval_dir = Path(Path().home(), \"temp\", \"03_introduction\")\n",
    "\n",
    "# Create an Evaluation object and create the directory\n",
    "ev = Evaluation(dir_path=test_eval_dir, create_dir=True)\n",
    "\n",
    "# Enable logging\n",
    "ev.enable_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clone Evaluation Data form S3\n",
    "As mentioned above, for this exercise we will be cloning a complete Evaluation dataset from the TEEHR S3 bucket.  First we will list the available Evaluations and then we will clone the `p0_2_location_example` evaluation which is  a small example Evaluation that conly contains 2 gages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0_2_location_example</td>\n",
       "      <td>Example evaluation datsets with 2 USGS gages</td>\n",
       "      <td>s3a://ciroh-rti-public-data/teehr-data-warehou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p1_camels_daily_streamflow</td>\n",
       "      <td>Daily average streamflow at ther Camels basins</td>\n",
       "      <td>s3a://ciroh-rti-public-data/teehr-data-warehou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p2_camels_hourly_streamflow</td>\n",
       "      <td>Hourly instantaneous streamflow at ther Camels...</td>\n",
       "      <td>s3a://ciroh-rti-public-data/teehr-data-warehou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p3_retro_hourly_streamflow</td>\n",
       "      <td>Hourly instantaneous streamflow at USGS CONUS ...</td>\n",
       "      <td>s3a://ciroh-rti-public-data/teehr-data-warehou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          name  \\\n",
       "0        p0_2_location_example   \n",
       "1   p1_camels_daily_streamflow   \n",
       "2  p2_camels_hourly_streamflow   \n",
       "3   p3_retro_hourly_streamflow   \n",
       "\n",
       "                                         description  \\\n",
       "0       Example evaluation datsets with 2 USGS gages   \n",
       "1     Daily average streamflow at ther Camels basins   \n",
       "2  Hourly instantaneous streamflow at ther Camels...   \n",
       "3  Hourly instantaneous streamflow at USGS CONUS ...   \n",
       "\n",
       "                                                 url  \n",
       "0  s3a://ciroh-rti-public-data/teehr-data-warehou...  \n",
       "1  s3a://ciroh-rti-public-data/teehr-data-warehou...  \n",
       "2  s3a://ciroh-rti-public-data/teehr-data-warehou...  \n",
       "3  s3a://ciroh-rti-public-data/teehr-data-warehou...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the evaluations in the S3 bucket\n",
    "ev.list_s3_evaluations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/05 14:43:44 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "24/11/05 14:43:57 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Clone the p0_2_location_example evaluation from the S3 bucket\n",
    "ev.clone_from_s3(\"p0_2_location_example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have cloned the `p0_2_location_example` evaluation, lets take a look at the data that was cloned from S3, specifically the `dataset` directory.  The three different data groups are stored in slightly different ways.  The domain tables (units, variables, configurations, attributes) are stored as *.csv files, the location tables (locations, location_attributes, location_crosswalks) are stored as parquet files without hive partitioning, and the timeseries tables (primary_timeseries, secondary_timeseries, joined_timeseries) are stored as parquet files with hive partitioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/Users/mdenno/temp/03_introduction/dataset\u001b[0m\n",
      "├── \u001b[01;34mattributes\u001b[0m\n",
      "│   └── \u001b[00mpart-00000-ebc3fa5d-f94e-4444-b0eb-8f410aa4b973-c000.csv\u001b[0m\n",
      "├── \u001b[01;34mconfigurations\u001b[0m\n",
      "│   └── \u001b[00mpart-00000-154140ef-341e-483d-9426-570acf5af026-c000.csv\u001b[0m\n",
      "├── \u001b[01;34mjoined_timeseries\u001b[0m\n",
      "│   └── \u001b[01;34mconfiguration_name=nwm30_retrospective\u001b[0m\n",
      "│       └── \u001b[01;34mvariable_name=streamflow_hourly_inst\u001b[0m\n",
      "│           └── \u001b[00mpart-00000-d72c9af4-ad9d-40ed-803d-0fdbfee97ab4.c000.snappy.parquet\u001b[0m\n",
      "├── \u001b[01;34mlocation_attributes\u001b[0m\n",
      "│   └── \u001b[00mpart-00000-b9f7fca2-1b91-40d1-a7ad-d9276802cbfc-c000.snappy.parquet\u001b[0m\n",
      "├── \u001b[01;34mlocation_crosswalks\u001b[0m\n",
      "│   └── \u001b[00mpart-00000-74f877cd-cf86-40c9-b604-6b97fc693a2e-c000.snappy.parquet\u001b[0m\n",
      "├── \u001b[01;34mlocations\u001b[0m\n",
      "│   └── \u001b[00mpart-00000-5b1e2b40-0f17-4391-9349-314a41bb15db-c000.snappy.parquet\u001b[0m\n",
      "├── \u001b[01;34mprimary_timeseries\u001b[0m\n",
      "│   └── \u001b[01;34mconfiguration_name=usgs_observations\u001b[0m\n",
      "│       └── \u001b[01;34mvariable_name=streamflow_hourly_inst\u001b[0m\n",
      "│           └── \u001b[00mpart-00000-c39532fd-1fd2-48ba-a65b-cac54fb28bfc.c000.snappy.parquet\u001b[0m\n",
      "├── \u001b[01;34msecondary_timeseries\u001b[0m\n",
      "│   └── \u001b[01;34mconfiguration_name=nwm30_retrospective\u001b[0m\n",
      "│       └── \u001b[01;34mvariable_name=streamflow_hourly_inst\u001b[0m\n",
      "│           └── \u001b[00mpart-00000-63dfc6b3-4ec8-43b6-a7e9-35fa59a0d175.c000.snappy.parquet\u001b[0m\n",
      "├── \u001b[01;34munits\u001b[0m\n",
      "│   └── \u001b[00mpart-00000-3ef0e6d4-8caa-4537-911b-0e7d4874e900-c000.csv\u001b[0m\n",
      "└── \u001b[01;34mvariables\u001b[0m\n",
      "    └── \u001b[00mpart-00000-e75cc646-22e6-4a52-9da4-43d7aa8b68d3-c000.csv\u001b[0m\n",
      "\n",
      "17 directories, 10 files\n"
     ]
    }
   ],
   "source": [
    "# from teehr.evaluation.utils import print_tree\n",
    "# print_tree(ev.dataset_dir, exclude_patterns=[\".*\", \"_*\"])\n",
    "!tree $HOME/temp/03_introduction/dataset -I \".*|_*\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table Classes\n",
    "The TEEHR Evaluation class contains different sub-classes that are used to oragnize class methods into logical groups.  One of these types of sub-classes is the \"table\" sub-classes which contain methods for interacting with the data tables. Each of the tables in the Evaluation dataset has a respective sub-class with the table name.\n",
    "```\n",
    "ev.units\n",
    "ev.attributes\n",
    "ev.variables\n",
    "ev.configurations\n",
    "ev.locations\n",
    "ev.location_attributes\n",
    "ev.location_crosswalks\n",
    "ev.primary_timeseries\n",
    "ev.secondary_timeseries\n",
    "ev.joined_timeseries\n",
    "```\n",
    "Each of the table sub-classes then has methods to add or insert new data ans well as methods to query the data out.  These are documented in the API documentation.\n",
    "\n",
    "NEED LINK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying\n",
    "The underlying query engine for TEEHR is PySpark.  Each of the table sub-classes can return data as either a Spark DataFrame (using the `to_sdf()` method) or as a Pandas DataFrame (using the `to_pandas()` method).  The location data tables have an additional method that returns a GeoPandas DataFrame (using the `to_geopandas()` method) where the geometry bytes column has been converted to a proper WKT geometry column.\n",
    "\n",
    "Note: PySpark itself is \"lazy loaded\" meaning that it does not actually run the query until the data is needed for display, plotting, etc.  Therefore, if you just use the `to_sdf()` method, you do not get the data but rather a lazy Spark DataFrame that can be used with subsequent Spark operations.  Here we show how to get the Spark DataFrame and show the data but there are many other ways that the lazy Spark DataFrame can be used in subsequent operations that are beyond the scope of this document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: string, name: string, geometry: binary]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query the locations and return as a lazy Spark DataFrame.\n",
    "ev.locations.to_sdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+--------------------+\n",
      "|           id|                name|            geometry|\n",
      "+-------------+--------------------+--------------------+\n",
      "|usgs-14316700|STEAMBOAT CREEK N...|[01 01 00 00 00 9...|\n",
      "|usgs-14138800|BLAZED ALDER CREE...|[01 01 00 00 00 B...|\n",
      "+-------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query the locations and return as a Spark DataFrame but tell Spark to show the data.\n",
    "ev.locations.to_sdf().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>usgs-14316700</td>\n",
       "      <td>STEAMBOAT CREEK NEAR GLIDE, OR</td>\n",
       "      <td>b'\\x01\\x01\\x00\\x00\\x00\\x9f\\xcc?\\xfa\\xa6\\xae^\\x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>usgs-14138800</td>\n",
       "      <td>BLAZED ALDER CREEK NEAR RHODODENDRON, OR</td>\n",
       "      <td>b'\\x01\\x01\\x00\\x00\\x00\\xb7\\xday\\xd1\\ry^\\xc0\\x1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                      name  \\\n",
       "0  usgs-14316700            STEAMBOAT CREEK NEAR GLIDE, OR   \n",
       "1  usgs-14138800  BLAZED ALDER CREEK NEAR RHODODENDRON, OR   \n",
       "\n",
       "                                            geometry  \n",
       "0  b'\\x01\\x01\\x00\\x00\\x00\\x9f\\xcc?\\xfa\\xa6\\xae^\\x...  \n",
       "1  b'\\x01\\x01\\x00\\x00\\x00\\xb7\\xday\\xd1\\ry^\\xc0\\x1...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query the locations and return as a Pandas DataFrame.\n",
    "# Note that the geometry column is shown as a byte string.\n",
    "ev.locations.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>usgs-14316700</td>\n",
       "      <td>STEAMBOAT CREEK NEAR GLIDE, OR</td>\n",
       "      <td>POINT (-122.72894 43.34984)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>usgs-14138800</td>\n",
       "      <td>BLAZED ALDER CREEK NEAR RHODODENDRON, OR</td>\n",
       "      <td>POINT (-121.89147 45.45262)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                      name  \\\n",
       "0  usgs-14316700            STEAMBOAT CREEK NEAR GLIDE, OR   \n",
       "1  usgs-14138800  BLAZED ALDER CREEK NEAR RHODODENDRON, OR   \n",
       "\n",
       "                      geometry  \n",
       "0  POINT (-122.72894 43.34984)  \n",
       "1  POINT (-121.89147 45.45262)  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query the locations and return as a GeoPandas DataFrame.\n",
    "# Note that the geometry column is now a proper WKT geometry column.\n",
    "ev.locations.to_geopandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter and Order\n",
    "Becasue the tables are a lazy loaded Spark DataFrames, we can filter and order the data before returning it as a Pandas or GeoPandas DataFrame. The filter methods take either a raw SQL string, a filter dictionary or a FilterObject and Operator and field enumeration. Using an FilterObject and Operator and field enumeration is probably not a common pattern for most users, it is used internally to validate filter arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:teehr.evaluation.tables:Setting filter <class 'filter'>.\n",
      "DEBUG:teehr.querying.filter_format:Filter id = 'usgs-14316700' is already string.  Applying as is.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>usgs-14316700</td>\n",
       "      <td>STEAMBOAT CREEK NEAR GLIDE, OR</td>\n",
       "      <td>POINT (-122.72894 43.34984)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                            name                     geometry\n",
       "0  usgs-14316700  STEAMBOAT CREEK NEAR GLIDE, OR  POINT (-122.72894 43.34984)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter using a raw SQL string\n",
    "ev.locations.filter(\"id = 'usgs-14316700'\").to_geopandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:teehr.evaluation.tables:Setting filter <class 'filter'>.\n",
      "DEBUG:teehr.querying.filter_format:Filter is not a list.  Making a list.\n",
      "DEBUG:teehr.querying.filter_format:Validating and applying {'column': 'id', 'operator': '=', 'value': 'usgs-14316700'}\n",
      "DEBUG:teehr.querying.filter_format:Filter: {\"column\":\"id\",\"operator\":\"=\",\"value\":\"usgs-14316700\"}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>usgs-14316700</td>\n",
       "      <td>STEAMBOAT CREEK NEAR GLIDE, OR</td>\n",
       "      <td>POINT (-122.72894 43.34984)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                            name                     geometry\n",
       "0  usgs-14316700  STEAMBOAT CREEK NEAR GLIDE, OR  POINT (-122.72894 43.34984)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter using a dictionary\n",
    "ev.locations.filter({\n",
    "    \"column\": \"id\",\n",
    "    \"operator\": \"=\",\n",
    "    \"value\": \"usgs-14316700\"\n",
    "}).to_geopandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:teehr.evaluation.tables:Setting filter <class 'filter'>.\n",
      "DEBUG:teehr.querying.filter_format:Filter is not a list.  Making a list.\n",
      "DEBUG:teehr.querying.filter_format:Validating and applying column=<LocationFields.id: 'id'> operator=<FilterOperators.eq: '='> value='usgs-14316700'\n",
      "DEBUG:teehr.querying.filter_format:Filter: {\"column\":\"id\",\"operator\":\"=\",\"value\":\"usgs-14316700\"}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>usgs-14316700</td>\n",
       "      <td>STEAMBOAT CREEK NEAR GLIDE, OR</td>\n",
       "      <td>POINT (-122.72894 43.34984)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                            name                     geometry\n",
       "0  usgs-14316700  STEAMBOAT CREEK NEAR GLIDE, OR  POINT (-122.72894 43.34984)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the LocationFilter and Operators classes\n",
    "from teehr import LocationFilter, Operators\n",
    "\n",
    "# Get the field enumeration\n",
    "fields = ev.locations.field_enum()\n",
    "\n",
    "# Filter using the LocationFilter class\n",
    "lf = LocationFilter(\n",
    "    column=fields.id,\n",
    "    operator=Operators.eq,\n",
    "    value=\"usgs-14316700\"\n",
    ")\n",
    "ev.locations.filter(lf).to_geopandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
